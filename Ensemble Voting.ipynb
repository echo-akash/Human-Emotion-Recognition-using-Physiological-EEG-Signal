{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc, roc_curve\n",
    "from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#load package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from math import sqrt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Feature/advanced+statistical_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = np.random.randn(df.shape[0], 1)\n",
    "\n",
    "msk = np.random.rand(len(df)) <= 0.7\n",
    "\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "\n",
    "x = train.drop(\"Level\", axis=1)\n",
    "y = train[\"Level\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.25,random_state=1)\n",
    "#print(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ensemble.BaggingClassifier()\n",
    "model2 = xgb.XGBClassifier()\n",
    "model3 = linear_model.LogisticRegressionCV()\n",
    "\n",
    "model = VotingClassifier(estimators=[('model1', model1), ('model2', model2), ('model3', model3)], voting='hard')\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n",
      "Accuracy: 0.62 (+/- 0.08) [Logistic Regression]\n",
      "Accuracy: 0.54 (+/- 0.10) [Random Forest]\n",
      "Accuracy: 0.55 (+/- 0.08) [Naive Bayes]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes']\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, x, y, \n",
    "                                              cv=5, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62 (+/- 0.08) [Logistic Regression]\n",
      "Accuracy: 0.54 (+/- 0.10) [Random Forest]\n",
      "Accuracy: 0.55 (+/- 0.08) [Naive Bayes]\n",
      "Accuracy: 0.60 (+/- 0.08) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1])\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, x, y, \n",
    "                                              cv=5, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X must be a NumPy array. Found <class 'pandas.core.frame.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-6dc0079fece1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgrd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_decision_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\mlxtend\\plotting\\decision_regions.py\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[1;34m(X, y, clf, feature_index, filler_feature_values, filler_feature_ranges, ax, X_highlight, res, zoom_factor, legend, hide_spines, markers, colors, scatter_kwargs, contourf_kwargs, scatter_highlight_kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mcheck_Xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Validate X and y arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\mlxtend\\utils\\checking.py\u001b[0m in \u001b[0;36mcheck_Xy\u001b[1;34m(X, y, y_int)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# check types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X must be a NumPy array. Found %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y must be a NumPy array. Found %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X must be a NumPy array. Found <class 'pandas.core.frame.DataFrame'>"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']\n",
    "for clf, lab, grd in zip([clf1, clf2, clf3, eclf],\n",
    "                         labels,\n",
    "                         itertools.product([0, 1], repeat=2)):\n",
    "\n",
    "    clf.fit(x, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(x, y, clf)\n",
    "    plt.title(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607 +/- 0.04 {'logisticregression__C': 1.0, 'randomforestclassifier__n_estimators': 20}\n",
      "0.607 +/- 0.03 {'logisticregression__C': 1.0, 'randomforestclassifier__n_estimators': 200}\n",
      "0.607 +/- 0.04 {'logisticregression__C': 100.0, 'randomforestclassifier__n_estimators': 20}\n",
      "0.607 +/- 0.03 {'logisticregression__C': 100.0, 'randomforestclassifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='soft')\n",
    "\n",
    "params = {'logisticregression__C': [1.0, 100.0],\n",
    "          'randomforestclassifier__n_estimators': [20, 200],}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid.fit(x, y)\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573 +/- 0.04 {'pipeline__logreg__C': 1.0, 'pipeline__sfs__k_features': 1, 'randomforestclassifier__n_estimators': 20}\n",
      "0.573 +/- 0.03 {'pipeline__logreg__C': 1.0, 'pipeline__sfs__k_features': 1, 'randomforestclassifier__n_estimators': 200}\n",
      "0.573 +/- 0.04 {'pipeline__logreg__C': 1.0, 'pipeline__sfs__k_features': 2, 'randomforestclassifier__n_estimators': 20}\n",
      "0.582 +/- 0.03 {'pipeline__logreg__C': 1.0, 'pipeline__sfs__k_features': 2, 'randomforestclassifier__n_estimators': 200}\n",
      "0.573 +/- 0.04 {'pipeline__logreg__C': 1.0, 'pipeline__sfs__k_features': 3, 'randomforestclassifier__n_estimators': 20}\n",
      "0.573 +/- 0.04 {'pipeline__logreg__C': 1.0, 'pipeline__sfs__k_features': 3, 'randomforestclassifier__n_estimators': 200}\n",
      "0.564 +/- 0.04 {'pipeline__logreg__C': 100.0, 'pipeline__sfs__k_features': 1, 'randomforestclassifier__n_estimators': 20}\n",
      "0.564 +/- 0.04 {'pipeline__logreg__C': 100.0, 'pipeline__sfs__k_features': 1, 'randomforestclassifier__n_estimators': 200}\n",
      "0.573 +/- 0.04 {'pipeline__logreg__C': 100.0, 'pipeline__sfs__k_features': 2, 'randomforestclassifier__n_estimators': 20}\n",
      "0.573 +/- 0.04 {'pipeline__logreg__C': 100.0, 'pipeline__sfs__k_features': 2, 'randomforestclassifier__n_estimators': 200}\n",
      "0.582 +/- 0.04 {'pipeline__logreg__C': 100.0, 'pipeline__sfs__k_features': 3, 'randomforestclassifier__n_estimators': 20}\n",
      "0.582 +/- 0.04 {'pipeline__logreg__C': 100.0, 'pipeline__sfs__k_features': 3, 'randomforestclassifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "# Creating a feature-selection-classifier pipeline\n",
    "\n",
    "sfs1 = SequentialFeatureSelector(clf1, \n",
    "                                 k_features=4,\n",
    "                                 forward=True, \n",
    "                                 floating=False, \n",
    "                                 scoring='accuracy',\n",
    "                                 verbose=0,\n",
    "                                 cv=0)\n",
    "\n",
    "clf1_pipe = Pipeline([('sfs', sfs1),\n",
    "                      ('logreg', clf1)])\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1_pipe, clf2, clf3], \n",
    "                              voting='soft')\n",
    "\n",
    "\n",
    "params = {'pipeline__sfs__k_features': [1, 2, 3],\n",
    "          'pipeline__logreg__C': [1.0, 100.0],\n",
    "          'randomforestclassifier__n_estimators': [20, 200]}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid.fit(x, y)\n",
    "\n",
    "\n",
    "\n",
    "cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_[cv_keys[0]][r],\n",
    "             grid.cv_results_[cv_keys[1]][r] / 2.0,\n",
    "             grid.cv_results_[cv_keys[2]][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00403871 0.32317541 0.36555215 0.30723373]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00403871 0.32317541 0.36555215 0.30723373]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00404585 0.32317333 0.36554963 0.30723119]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.00403871 0.32317541 0.36555215 0.30723373]\n",
      "Class from SVM             : 1\n",
      "Probas from SVM in Ensemble: [0.00403871 0.32317541 0.36555215 0.30723373]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365851 0.00400726 0.36508777 0.30724646]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365851 0.00400726 0.36508777 0.30724646]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365646 0.00401438 0.36508523 0.30724393]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32365851 0.00400726 0.36508777 0.30724646]\n",
      "Class from SVM             : 2\n",
      "Probas from SVM in Ensemble: [0.32365851 0.00400726 0.36508777 0.30724646]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM             : 3\n",
      "Probas from SVM in Ensemble: [0.33511976 0.33535251 0.00646791 0.32305982]\n",
      "Class from SVM in Ensemble : 2\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n",
      "============\n",
      "Probas from SVM            : [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM             : 4\n",
      "Probas from SVM in Ensemble: [0.32116698 0.3174597  0.35743747 0.00393584]\n",
      "Class from SVM in Ensemble : 3\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "clf2 = SVC(probability=True, random_state=4)\n",
    "clf2.fit(x, y)\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf2], voting='soft', refit=False)\n",
    "eclf.fit(x, y)\n",
    "\n",
    "for svm_class, e_class, svm_prob, e_prob, in zip(clf2.predict(x),\n",
    "                                                 eclf.predict(x),\n",
    "                                                 clf2.predict_proba(x),\n",
    "                                                 eclf.predict_proba(x)):\n",
    "    if svm_class != e_class:\n",
    "        print('============')\n",
    "        print('Probas from SVM            :', svm_prob)\n",
    "        print('Class from SVM             :', svm_class)\n",
    "        print('Probas from SVM in Ensemble:', e_prob)\n",
    "        print('Class from SVM in Ensemble :', e_class)\n",
    "        print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[Pipeline(memory=None,\n",
       "                                      steps=[('columnselector',\n",
       "                                              ColumnSelector(cols=(0, 2),\n",
       "                                                             drop_axis=False)),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=100,\n",
       "                                                                 multi_class='warn',\n",
       "                                                                 n_jobs=None,\n",
       "                                                                 penalty='l2',\n",
       "                                                                 random_state=None,\n",
       "                                                                 solver='warn',\n",
       "                                                                 tol=0.0001,\n",
       "                                                                 ve...\n",
       "                                              ColumnSelector(cols=(1, 2, 3),\n",
       "                                                             drop_axis=False)),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=100,\n",
       "                                                                 multi_class='warn',\n",
       "                                                                 n_jobs=None,\n",
       "                                                                 penalty='l2',\n",
       "                                                                 random_state=None,\n",
       "                                                                 solver='warn',\n",
       "                                                                 tol=0.0001,\n",
       "                                                                 verbose=0,\n",
       "                                                                 warm_start=False))],\n",
       "                                      verbose=False)],\n",
       "                       refit=True, verbose=0, voting='hard', weights=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "pipe1 = make_pipeline(ColumnSelector(cols=(0, 2)),\n",
    "                      LogisticRegression())\n",
    "pipe2 = make_pipeline(ColumnSelector(cols=(1, 2, 3)),\n",
    "                      LogisticRegression())\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[pipe1, pipe2])\n",
    "\n",
    "eclf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn. ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc, roc_curve, classification_report, roc_auc_score\n",
    "from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Feature/advanced+statistical_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = data.drop(\"Level\", axis=1)\n",
    "df_y = data[\"Level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest - Ensemble of Descision Trees\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient boosting\n",
    "gb = ensemble.GradientBoostingClassifier()\n",
    "gb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=0.5, n_estimators=20, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bagging \n",
    "\n",
    "bg = BaggingClassifier(DecisionTreeClassifier(), max_samples= 0.5, max_features = 1.0, n_estimators = 20)\n",
    "bg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=None,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=1, n_estimators=5, random_state=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Boosting - Ada Boost\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(),n_estimators = 5, learning_rate = 1)\n",
    "adb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extra trees\n",
    "et=ensemble.ExtraTreesClassifier()\n",
    "et.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier - Multiple Model Ensemble \n",
    "\n",
    "lr = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "svm = SVC(kernel = 'poly', degree = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "evc = VotingClassifier( estimators= [('lr',lr),('dt',dt),('svm',svm)], voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\thinkpad\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='warn', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,...\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best')),\n",
       "                             ('svm',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=2, gamma='auto_deprecated',\n",
       "                                  kernel='poly', max_iter=-1, probability=False,\n",
       "                                  random_state=None, shrinking=True, tol=0.001,\n",
       "                                  verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
